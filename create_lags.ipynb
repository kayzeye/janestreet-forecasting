{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a20d9c5-ae45-491c-8a6c-ee712c23158a",
   "metadata": {},
   "source": [
    "# Basically copied from https://www.kaggle.com/code/motono0223/js24-preprocessing-create-lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb807450-9693-49a6-89dd-8a0ff002e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9f16a0-3ca1-4ec5-af11-dd3af5146885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  8 22:20:31 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   46C    P3             25W /  170W |     695MiB /  12288MiB |     14%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47139ff3-a7cc-458b-b0c5-903967e4ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, gc\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1695d043-1129-44a1-9eb6-bba03ce39fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 0 objects.\n"
     ]
    }
   ],
   "source": [
    "collected = gc.collect()\n",
    "# Prints Garbage collector \n",
    "# as 0 object\n",
    "print(\"Garbage collector: collected\",\n",
    "          \"%d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90415b-740d-43b6-aa52-29a3616364dd",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6881a8-b962-4aba-a6ae-532af3040a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    target_col = \"responder_6\"\n",
    "    lag_cols_original = [\"date_id\", \"symbol_id\"] + [f\"responder_{idx}\" for idx in range(9)]\n",
    "    lag_cols_rename = {f\"responder_{idx}\" : f\"responder_{idx}_lag_1\" for idx in range(9)}\n",
    "    valid_ratio = 0.20\n",
    "    start_dt = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e0046-0579-42bb-a25b-9f0f8c85f60f",
   "metadata": {},
   "source": [
    "# load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3816a74c-9d12-435f-a0f5-c59dabd28097",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "SAVE = True\n",
    "PATH = os.getcwd() + '/input/'\n",
    "if TEST:\n",
    "    CONFIG.start_dt = 1100\n",
    "    train_df = pl.scan_parquet(PATH+'train.parquet/partition_id=*/*.parquet').select(\n",
    "        pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\"),\n",
    "        pl.all(),\n",
    "    ).with_columns(\n",
    "        (pl.col(CONFIG.target_col)*2).cast(pl.Int32).alias(\"label\"),\n",
    "    ).filter(\n",
    "        pl.col(\"date_id\").gt(CONFIG.start_dt)\n",
    "    )\n",
    "else:\n",
    "    train_df = pl.scan_parquet(PATH+'train.parquet/partition_id=*/*.parquet').select(\n",
    "        pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\"),\n",
    "        pl.all(),\n",
    "    ).with_columns(\n",
    "        (pl.col(CONFIG.target_col)*2).cast(pl.Int32).alias(\"label\"),\n",
    "    ).filter(\n",
    "        pl.col(\"date_id\").gt(CONFIG.start_dt)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed4433-512f-4031-8dcd-31b95e9c6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee9944-80f3-4cc6-a98d-11cd96f4bf0b",
   "metadata": {},
   "source": [
    "# Create lags data from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f27550-6116-4eb3-8829-6213db013bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = train_df.select(pl.col(CONFIG.lag_cols_original))\n",
    "lags = lags.rename(CONFIG.lag_cols_rename)\n",
    "lags = lags.with_columns(\n",
    "    date_id = pl.col('date_id') + 1,  # lagged by 1 day\n",
    "    )\n",
    "lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()  # pick up last record of previous date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335a673e-340d-43d7-87c1-9734ddb8a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.join(lags, on=[\"date_id\", \"symbol_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfcbed1-96ab-4d35-b287-be5a36834a91",
   "metadata": {},
   "source": [
    "# Split training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4f82f0-c8a9-4753-bd61-cdf081f2a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " len_train = 46139102\n",
      "\n",
      " len_ofl_mdl = 36911282\n",
      "\n",
      "---> Last offline train date = 1448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len_train = train_df.select(pl.col(\"date_id\")).collect().shape[0]\n",
    "valid_records = int(len_train * CONFIG.valid_ratio)\n",
    "len_ofl_mdl = len_train - valid_records # length of offline model train data\n",
    "last_tr_dt = train_df.select(pl.col(\"date_id\")).collect().row(len_ofl_mdl)[0]\n",
    "\n",
    "print(f\"\\n len_train = {len_train}\")\n",
    "print(f\"\\n len_ofl_mdl = {len_ofl_mdl}\")\n",
    "print(f\"\\n---> Last offline train date = {last_tr_dt}\\n\")\n",
    "\n",
    "training_data = train_df.filter(pl.col(\"date_id\").le(last_tr_dt))\n",
    "validation_data   = train_df.filter(pl.col(\"date_id\").gt(last_tr_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbcfd32-442c-4e2d-b452-e3e2cd437684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_data.show_graph() # I don't have graphviz installed lmao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271d074-75ee-49d8-b524-d5f3a13c6eee",
   "metadata": {},
   "source": [
    "# Save data as parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858e2b33-d1ee-4bdd-9ee1-a3d823a94fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST and SAVE:\n",
    "    training_data.collect().write_parquet(f\"./input/training_TEST.parquet\")\n",
    "    validation_data.collect().write_parquet(f\"./input/validation_TEST.parquet\")\n",
    "elif not TEST and SAVE:\n",
    "    training_data.collect().write_parquet(f\"./input/training_gt100.parquet\", partition_by=\"date_id\")\n",
    "    validation_data.collect().write_parquet(f\"./input/validation_gt100.parquet\", partition_by=\"date_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03109a83-7784-4991-99df-1567c916adb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
