{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  8 02:34:28 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   41C    P5             21W /  170W |     967MiB /  12288MiB |     44%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, gc\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import random\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "#import catboost as cbt # needs numpy <2.0\n",
    "import numpy as np\n",
    "#from hyperopt import hp, fmin, tpe, Trials\n",
    "#from hyperopt.pyll.base import scope\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm.notebook import tqdm\n",
    "#from joblib import dump, load\n",
    "#import datatable as dtable\n",
    "#from mlxtend.evaluate import GroupTimeSeriesSplit\n",
    "import kaggle_evaluation.jane_street_inference_server as js_server\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# check that torch is working and sees the GPU\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 72 objects.\n"
     ]
    }
   ],
   "source": [
    "collected = gc.collect()\n",
    "# Prints Garbage collector \n",
    "# as 0 object\n",
    "print(\"Garbage collector: collected\",\n",
    "          \"%d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_7', 'responder_8', 'responder_0_lag_1', 'responder_1_lag_1', 'responder_2_lag_1', 'responder_3_lag_1', 'responder_4_lag_1', 'responder_5_lag_1', 'responder_6_lag_1', 'responder_7_lag_1', 'responder_8_lag_1']\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd() + '/input/'\n",
    "\n",
    "METAS = ['date_id', 'time_id', 'symbol_id', 'weight']\n",
    "FEATURES = [f'feature_{i:02}' for i in range(79)]\n",
    "RESPONDERS = [f'responder_{i}' for i in range(9)]\n",
    "RESPONDERS_LAGS = [f'responder_{i}_lag_1' for i in range(9)]\n",
    "TARGET = 'responder_6'\n",
    "FEATURES_AND_LAGS=True\n",
    "if FEATURES_AND_LAGS:\n",
    "    FEATURES_WORKING = FEATURES + RESPONDERS + RESPONDERS_LAGS\n",
    "    FEATURES_WORKING.remove(TARGET)\n",
    "else:\n",
    "    FEATURES_WORKING = FEATURES\n",
    "print(FEATURES_WORKING)\n",
    "SEQUENCE_LEN = 16 # not sure what this is for\n",
    "\n",
    "SEED = 728\n",
    "\n",
    "TEST=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Ensure deterministic behavior (may impact performance)\n",
    "        #torch.backends.cudnn.deterministic = False\n",
    "        #torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def lazy_load(par_path):\n",
    "    return pl.scan_parquet(par_path).select(\n",
    "        pl.int_range(pl.len(), dtype=pl.UInt64).alias(\"index\"),\n",
    "        pl.all()\n",
    "    )\n",
    "seed_everything(SEED) # just do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use synthetic test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is just copied boilerplate, don't have synthetic testing atm\n",
    "# USE_SYNTHETIC = False\n",
    "\n",
    "# if USE_SYNTHETIC:\n",
    "#     syn_dir = '/kaggle/input/js24-rmf-generate-synthetic-test-data'\n",
    "#     test_parquet = f'{syn_dir}/synthetic_test.parquet'\n",
    "#     lag_parquet = f'{syn_dir}/synthetic_lag.parquet'\n",
    "#     total_time_steps = pl.scan_parquet(test_parquet).select(\n",
    "#         (pl.col(\"date_id\")*10000+pl.col('time_id')).n_unique()   \n",
    "#         ).collect().item()\n",
    "# else:\n",
    "#     test_parquet_path = PATH + 'test.parquet/'\n",
    "#     lag_parquet_path =  PATH + 'lags.parquet/'\n",
    "#     total_time_steps = 1\n",
    "    \n",
    "# print(\"Test parquet:\", test_parquet_path)\n",
    "# print(\"Lag parquet:\", lag_parquet_path)\n",
    "# print(\"Total time steps:\", total_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TEST:\n",
    "    train_df = pl.read_parquet(PATH+'training_TEST.parquet') # this parquet has lags\n",
    "    valid_df = pl.read_parquet(PATH+'validation_TEST.parquet') # this parquet has lags\n",
    "else:\n",
    "    train_df = pl.scan_parquet(PATH+'training.parquet').collect() # I think this will scan over all the subdirs, also thise has lags\n",
    "    valid_df = pl.scan_parquet(PATH+'validation.parquet').collect()\n",
    "\n",
    "feature_tags = pl.read_csv(PATH+'features.csv') # no one seems to use this....\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling...\n",
      "True\n",
      "shape: (5, 103)\n",
      "┌────────────┬─────────┬─────────┬───────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
      "│ id         ┆ date_id ┆ time_id ┆ symbol_id ┆ … ┆ responder_ ┆ responder_ ┆ responder ┆ responder │\n",
      "│ ---        ┆ ---     ┆ ---     ┆ ---       ┆   ┆ 5_lag_1    ┆ 6_lag_1    ┆ _7_lag_1  ┆ _8_lag_1  │\n",
      "│ f64        ┆ f64     ┆ f64     ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
      "│            ┆         ┆         ┆           ┆   ┆ f32        ┆ f32        ┆ f32       ┆ f32       │\n",
      "╞════════════╪═════════╪═════════╪═══════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
      "│ 2.5023058e ┆ 1101.0  ┆ 0.0     ┆ 0.0       ┆ … ┆ 0.112157   ┆ 0.011801   ┆ 0.033876  ┆ 0.009129  │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "│ 2.5023059e ┆ 1101.0  ┆ 0.0     ┆ 1.0       ┆ … ┆ 0.112157   ┆ 0.011801   ┆ 0.033876  ┆ 0.009129  │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "│ 2.502306e7 ┆ 1101.0  ┆ 0.0     ┆ 2.0       ┆ … ┆ 0.112157   ┆ 0.011801   ┆ 0.033876  ┆ 0.009129  │\n",
      "│ 2.5023061e ┆ 1101.0  ┆ 0.0     ┆ 3.0       ┆ … ┆ 0.112157   ┆ 0.011801   ┆ 0.033876  ┆ 0.009129  │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "│ 2.5023062e ┆ 1101.0  ┆ 0.0     ┆ 4.0       ┆ … ┆ 0.112157   ┆ 0.011801   ┆ 0.033876  ┆ 0.009129  │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "└────────────┴─────────┴─────────┴───────────┴───┴────────────┴────────────┴───────────┴───────────┘\n",
      "shape: (5, 103)\n",
      "┌────────────┬─────────┬─────────┬───────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
      "│ id         ┆ date_id ┆ time_id ┆ symbol_id ┆ … ┆ responder_ ┆ responder_ ┆ responder ┆ responder │\n",
      "│ ---        ┆ ---     ┆ ---     ┆ ---       ┆   ┆ 5_lag_1    ┆ 6_lag_1    ┆ _7_lag_1  ┆ _8_lag_1  │\n",
      "│ f64        ┆ f64     ┆ f64     ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
      "│            ┆         ┆         ┆           ┆   ┆ f32        ┆ f32        ┆ f32       ┆ f32       │\n",
      "╞════════════╪═════════╪═════════╪═══════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
      "│ 4.492901e7 ┆ 1640.0  ┆ 0.0     ┆ 0.0       ┆ … ┆ 1.407963   ┆ 0.171109   ┆ 0.095809  ┆ 0.272944  │\n",
      "│ 4.4929011e ┆ 1640.0  ┆ 0.0     ┆ 1.0       ┆ … ┆ 0.294283   ┆ -0.049461  ┆ 0.004138  ┆ -0.109695 │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "│ 4.4929012e ┆ 1640.0  ┆ 0.0     ┆ 2.0       ┆ … ┆ -0.835862  ┆ 0.101792   ┆ 0.068465  ┆ 0.194597  │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "│ 4.4929013e ┆ 1640.0  ┆ 0.0     ┆ 4.0       ┆ … ┆ 0.33488    ┆ 0.288235   ┆ 0.2094    ┆ 0.725253  │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "│ 4.4929014e ┆ 1640.0  ┆ 0.0     ┆ 5.0       ┆ … ┆ -0.838973  ┆ -0.015379  ┆ 0.029595  ┆ -0.054443 │\n",
      "│ 7          ┆         ┆         ┆           ┆   ┆            ┆            ┆           ┆           │\n",
      "└────────────┴─────────┴─────────┴───────────┴───┴────────────┴────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print('Filling...')\n",
    "print(train_df[\"weight\"].gt(0).sum() == train_df.shape[0]) # check if weights>0 is true for entire dataframe\n",
    "train_df = train_df.select([\n",
    "    pl.col(c).fill_null(pl.col(c).mean()).alias(c) for c in train_df.columns\n",
    "])\n",
    "print(train_df.head())\n",
    "\n",
    "valid_df = valid_df.select([\n",
    "    pl.col(c).fill_null(pl.col(c).mean()).alias(c) for c in valid_df.columns\n",
    "])\n",
    "print(valid_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for the purged group time series split, code is copied from somewhere\n",
    "# TODO: make GitHub GIST\n",
    "# TODO: add as dataset\n",
    "# TODO: add logging with verbose\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.|\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from matplotlib.colors import ListedColormap\n",
    "    \n",
    "# # this is code slightly modified from the sklearn docs here:\n",
    "# # https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "# def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "#     \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "#     cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "#     jet = plt.cm.get_cmap('jet', 256)\n",
    "#     seq = np.linspace(0, 1, 256)\n",
    "#     _ = np.random.shuffle(seq)   # inplace\n",
    "#     cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "#     # Generate the training/testing visualizations for each CV split\n",
    "#     for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "#         # Fill in indices with the training/test groups\n",
    "#         indices = np.array([np.nan] * len(X))\n",
    "#         indices[tt] = 1\n",
    "#         indices[tr] = 0\n",
    "\n",
    "#         # Visualize the results\n",
    "#         ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "#                    c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "#                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "#     # Plot the data classes and groups at the end\n",
    "#     ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "#                c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "#     ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "#                c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "#     # Formatting\n",
    "#     yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "#     ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "#            xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "#            ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "#     ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "#     return ax\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# #plot_cv_indices(cv, X_train, y_train, groups, ax, 5, lw=20)\n",
    "# plot_cv_indices(\n",
    "#     cv,\n",
    "#     train[features].values,\n",
    "#     train['responder_6'].values,\n",
    "#     train['date_id'].values,\n",
    "#     ax,\n",
    "#     5,\n",
    "#     lw=20\n",
    "# )\n",
    "# rubbish=gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code structure copied/inspired from https://www.kaggle.com/code/shiyili/js2024-rmf-mlp-inference-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "### Define various helper functions including r2 score\n",
    "writer = SummaryWriter()\n",
    "# get cpu, gpu or mps device for training\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def reset_weights(m):\n",
    "    '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "    '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# for monitoring layer weights\n",
    "def weight_histograms(writer, step, model):\n",
    "    print(\"Visualizing model weights...\")\n",
    "    # Iterate over all model layers\n",
    "    for layer_number in range(len(model.layers)):\n",
    "        layer = model.layers[layer_number]\n",
    "        try:\n",
    "            weights = layer.weight\n",
    "            flattened_weights = weights.flatten()\n",
    "            tag = f\"layer_{layer_number}\"\n",
    "            writer.add_histogram(tag, flattened_weights, global_step=step, bins='tensorflow')\n",
    "        except AttributeError:\n",
    "            return\n",
    "            \n",
    "# loss is as defined on competition homepage\n",
    "# score will be = 1 - loss\n",
    "def r2_loss(outputs, targets, weights):\n",
    "    loss = torch.sum(weights*(targets - outputs)**2) / (torch.sum(weights*targets**2)+1e-38)\n",
    "    return loss\n",
    "\n",
    "# \"standard\" loss function\n",
    "test_loss_function= nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_dim, hidden_size=self.hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# copied LSTM equivalent model\n",
    "class LSTMEquavalentMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMEquavalentMLP, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_gate = nn.Linear(input_size, hidden_size)\n",
    "        self.candidate_gate = nn.Linear(input_size, hidden_size)\n",
    "        self.output_gate = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i_t = torch.sigmoid(self.input_gate(x)) # input gate\n",
    "        c_t = torch.tanh(self.candidate_gate(x)) # candidate gate\n",
    "        o_t = torch.sigmoid(self.output_gate(x)) # output gate\n",
    "        \n",
    "        h_t = o_t * torch.tanh(c_t * i_t)\n",
    "        \n",
    "        return h_t\n",
    "    \n",
    "class LSTMFeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rates=0):\n",
    "        super(LSTMFeedForward, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm = LSTMEquavalentMLP(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_t = self.lstm(x)\n",
    "        y = self.fc(h_t).squeeze()\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(model, trainloader, optimizer, num_epochs, writer, save=True):\n",
    "    model.train()\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # Visualize weight histograms\n",
    "        #weight_histograms(writer, epoch, model)\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        \n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "        # Iterate over Dataloader for training data\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # Get inputs\n",
    "            inputs, targets, weights = data\n",
    "            # GPU must see the data and the model\n",
    "            inputs = inputs.to(device) \n",
    "            targets = targets.to(device)\n",
    "            weights = weights.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = r2_loss(outputs, targets, weights)\n",
    "            current_loss += loss.item()\n",
    "            if i % 1000 == 0:\n",
    "                print('Loss after mini-batch %5d: %.3f' %\n",
    "                      (i + 1, current_loss / 1000))\n",
    "                current_loss = 0.0\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "        # Finished iterating over Dataloader\n",
    "        writer.add_scalar(\"Loss/train/epoch\", loss, epoch)\n",
    "        writer.flush()\n",
    "      \n",
    "    # Saving the model\n",
    "    if save:\n",
    "        save_path = f'./models/lstm_{fold}.pth'\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    return\n",
    "\n",
    "# testing function\n",
    "def test(model, testloader, writer):\n",
    "    # Evaluation for this fold\n",
    "    R2_score = 0.0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(testloader):\n",
    "            # Get inputs\n",
    "            inputs, targets, weights = data\n",
    "            inputs = inputs.to(device) # GPU must see the data and the model\n",
    "            targets = targets.to(device)\n",
    "            weights = weights.to(device)\n",
    "        \n",
    "            # Generate outputs\n",
    "            outputs = model(inputs)\n",
    "            loss = r2_loss(outputs, targets, weights)\n",
    "            # writer.add_scalar('Loss/test/minibatches', loss, batch_test_tally)\n",
    "            # batch_test_tally += 1\n",
    "            total_loss += loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_FF_CONFIG = {\n",
    "    'input_size':  len(FEATURES_WORKING),\n",
    "    'hidden_size': 64,\n",
    "    'output_size': 1,\n",
    "    'dropout_rates': 0\n",
    "}\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    'num_folds': 1,\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 1e-4,\n",
    "    'test_loss': False\n",
    "}\n",
    "\n",
    "fold_function = 'PurgedGroupTimeSeries'\n",
    "# fold_function = 'KFold'\n",
    "fold_function = 'None'\n",
    "\n",
    "# For holding fold results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should test models with only features, features + responders, + lags, etc...\n",
    "if fold_function == 'PurgedGroupTimeSeries':\n",
    "    X = train_df[FEATURES_WORKING].to_numpy()\n",
    "    y = train_df[TARGET].to_numpy()\n",
    "    group = train_df['date_id'].to_numpy()\n",
    "    w = train_df['weight'].to_numpy()\n",
    "    # Define the PurgedGroupTimeSeriesCV\n",
    "    cv = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=folds,\n",
    "    max_train_group_size=80,\n",
    "    group_gap=10,\n",
    "    max_test_group_size=20\n",
    "    )\n",
    "    folds = cv.split(X=X, y=y, groups=group)\n",
    "elif fold_function == 'KFold': # TODO\n",
    "    folds = _\n",
    "elif fold_function == 'None' :\n",
    "    folds = [([0,0],[0,0])]\n",
    "    X_tr, y_tr, w_tr = train_df[FEATURES_WORKING].to_numpy(), train_df[TARGET].to_numpy(), train_df['weight'].to_numpy()\n",
    "    X_te, y_te, w_te = valid_df[FEATURES_WORKING].to_numpy(), valid_df[TARGET].to_numpy(), valid_df['weight'].to_numpy()\n",
    "else:\n",
    "    folds = _\n",
    "#neat hack to ensure the original dataframe is gone\n",
    "del train_df, valid_df\n",
    "gc.collect()\n",
    "train_df = pl.DataFrame()\n",
    "valid_df = pl.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "train_ids: [0, 0]\n",
      "test_ids: [0, 0]\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Linear(in_features=96, out_features=64, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=96, out_features=64, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=96, out_features=64, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=64, out_features=1, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch  1001: 0.802\n",
      "Loss after mini-batch  2001: 0.372\n",
      "Loss after mini-batch  3001: 0.160\n",
      "Loss after mini-batch  4001: 0.101\n",
      "Loss after mini-batch  5001: 0.097\n",
      "Loss after mini-batch  6001: 0.505\n",
      "Loss after mini-batch  7001: 0.362\n",
      "Loss after mini-batch  8001: 0.693\n",
      "Loss after mini-batch  9001: 0.459\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.135\n",
      "Loss after mini-batch  2001: 0.105\n",
      "Loss after mini-batch  3001: 0.127\n",
      "Loss after mini-batch  4001: 0.098\n",
      "Loss after mini-batch  5001: 0.096\n",
      "Loss after mini-batch  6001: 0.308\n",
      "Loss after mini-batch  7001: 0.236\n",
      "Loss after mini-batch  8001: 0.457\n",
      "Loss after mini-batch  9001: 0.313\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.123\n",
      "Loss after mini-batch  2001: 0.106\n",
      "Loss after mini-batch  3001: 0.124\n",
      "Loss after mini-batch  4001: 0.098\n",
      "Loss after mini-batch  5001: 0.095\n",
      "Loss after mini-batch  6001: 0.187\n",
      "Loss after mini-batch  7001: 0.166\n",
      "Loss after mini-batch  8001: 0.321\n",
      "Loss after mini-batch  9001: 0.195\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.114\n",
      "Loss after mini-batch  2001: 0.101\n",
      "Loss after mini-batch  3001: 0.123\n",
      "Loss after mini-batch  4001: 0.096\n",
      "Loss after mini-batch  5001: 0.092\n",
      "Loss after mini-batch  6001: 0.145\n",
      "Loss after mini-batch  7001: 0.140\n",
      "Loss after mini-batch  8001: 0.233\n",
      "Loss after mini-batch  9001: 0.137\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.104\n",
      "Loss after mini-batch  2001: 0.093\n",
      "Loss after mini-batch  3001: 0.117\n",
      "Loss after mini-batch  4001: 0.092\n",
      "Loss after mini-batch  5001: 0.089\n",
      "Loss after mini-batch  6001: 0.126\n",
      "Loss after mini-batch  7001: 0.125\n",
      "Loss after mini-batch  8001: 0.182\n",
      "Loss after mini-batch  9001: 0.128\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.098\n",
      "Loss after mini-batch  2001: 0.089\n",
      "Loss after mini-batch  3001: 0.112\n",
      "Loss after mini-batch  4001: 0.089\n",
      "Loss after mini-batch  5001: 0.087\n",
      "Loss after mini-batch  6001: 0.119\n",
      "Loss after mini-batch  7001: 0.119\n",
      "Loss after mini-batch  8001: 0.152\n",
      "Loss after mini-batch  9001: 0.119\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.094\n",
      "Loss after mini-batch  2001: 0.085\n",
      "Loss after mini-batch  3001: 0.109\n",
      "Loss after mini-batch  4001: 0.087\n",
      "Loss after mini-batch  5001: 0.085\n",
      "Loss after mini-batch  6001: 0.112\n",
      "Loss after mini-batch  7001: 0.115\n",
      "Loss after mini-batch  8001: 0.136\n",
      "Loss after mini-batch  9001: 0.112\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.091\n",
      "Loss after mini-batch  2001: 0.083\n",
      "Loss after mini-batch  3001: 0.107\n",
      "Loss after mini-batch  4001: 0.086\n",
      "Loss after mini-batch  5001: 0.084\n",
      "Loss after mini-batch  6001: 0.103\n",
      "Loss after mini-batch  7001: 0.114\n",
      "Loss after mini-batch  8001: 0.128\n",
      "Loss after mini-batch  9001: 0.110\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.089\n",
      "Loss after mini-batch  2001: 0.082\n",
      "Loss after mini-batch  3001: 0.105\n",
      "Loss after mini-batch  4001: 0.085\n",
      "Loss after mini-batch  5001: 0.084\n",
      "Loss after mini-batch  6001: 0.100\n",
      "Loss after mini-batch  7001: 0.109\n",
      "Loss after mini-batch  8001: 0.124\n",
      "Loss after mini-batch  9001: 0.108\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch  1001: 0.088\n",
      "Loss after mini-batch  2001: 0.082\n",
      "Loss after mini-batch  3001: 0.103\n",
      "Loss after mini-batch  4001: 0.085\n",
      "Loss after mini-batch  5001: 0.083\n",
      "Loss after mini-batch  6001: 0.098\n",
      "Loss after mini-batch  7001: 0.106\n",
      "Loss after mini-batch  8001: 0.122\n",
      "Loss after mini-batch  9001: 0.107\n",
      "Training process has finished\n",
      "Starting testing\n",
      "CROSS VALIDATION RESULTS FOR [([0, 0], [0, 0])] FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 0.1555556207895279\n",
      "Average: 0.1555556207895279\n"
     ]
    }
   ],
   "source": [
    "### Train and cross validation loop\n",
    "for fold, (train_ids, test_ids) in enumerate(folds):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print(f'train_ids: [{train_ids[0]}, {train_ids[-1]}]')\n",
    "    print(f'test_ids: [{test_ids[0]}, {test_ids[-1]}]')\n",
    "    if fold_function != 'None':\n",
    "        print(\"Using a fold function...\")\n",
    "        # define train/test sets\n",
    "        X_tr, y_tr, w_tr = X[train_ids], y[train_ids], w[train_ids]\n",
    "        X_te, y_te, w_te = X[test_ids], y[test_ids], w[test_ids]\n",
    "    \n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Initialize Dataset objects to make PyTorch play nice\n",
    "    trainset = TensorDataset(torch.tensor(X_tr).to(torch.float32), torch.tensor(y_tr), torch.tensor(w_tr))\n",
    "    testset = TensorDataset(torch.tensor(X_te).to(torch.float32), torch.tensor(y_te), torch.tensor(w_te))\n",
    "    \n",
    "    # Define data loaders\n",
    "    BATCH_SIZE = 2048\n",
    "    NUM_WORKERS = 4 # num of parallel subprocesses for data loading (CPU task)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers = NUM_WORKERS\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers = NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    # Init the model\n",
    "    model = LSTMFeedForward(**LSTM_FF_CONFIG).to(device)\n",
    "    model.apply(reset_weights) # not sure if I need this but w/e\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=TRAINING_CONFIG['learning_rate'])\n",
    "    train(model, trainloader, optimizer, TRAINING_CONFIG[\"num_epochs\"], writer, save=True)\n",
    "    # Process is complete.\n",
    "    print('Training process has finished')\n",
    "    \n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "    \n",
    "    total_loss = test(model, testloader, writer)\n",
    "    num_batches = len(testloader)\n",
    "    results[fold] = total_loss / num_batches\n",
    "    writer.add_scalar('Loss/test/fold', results[fold], fold)\n",
    "    writer.flush()\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f'CROSS VALIDATION RESULTS FOR {folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value}')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())}')\n",
    "writer.close()\n",
    "rubbish=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmao\n",
    "# out = outputs.cpu().detach().numpy()\n",
    "# tar = targets.cpu().detach().numpy()\n",
    "# wei = weights.cpu().detach().numpy()\n",
    "# print(out[10,0])\n",
    "# nbins = 20\n",
    "# plt.hist(tar, color='orange', label='targets', bins=nbins)\n",
    "# plt.hist(wei, color='green', label='weights', bins=nbins)\n",
    "# plt.hist(out[:,0], color='blue', bins=nbins, label='predicted')\n",
    "# plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
